import streamlit as st
import pandas as pd
import zipfile
import google.generativeai as genai
import io
import matplotlib.pyplot as plt
import seaborn as sns
import json

# =============================================================================
# 1. CONFIGURA√á√ÉO DA P√ÅGINA E ESTILO
# =============================================================================
st.set_page_config(layout="centered", page_title="Data Insights", page_icon="üçè")

def load_css():
    st.markdown("""
    <style>
        html, body, [class*="st-"] {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji";
        }
        [data-testid="stChatMessage"] {
            border-radius: 18px;
            padding: 1em 1.2em;
            margin-bottom: 1em;
            box-shadow: 0 4px 12px rgba(0,0,0,0.05);
            border: 1px solid rgba(0,0,0,0.05);
        }
        .block-container { max-width: 800px; padding-top: 3rem; padding-bottom: 3rem; }
    </style>
    """, unsafe_allow_html=True)

load_css()

# =============================================================================
# 2. CONFIGURA√á√ÉO DO MODELO DE IA (GEMINI)
# =============================================================================
try:
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=GOOGLE_API_KEY)
    model = genai.GenerativeModel('gemini-1.5-flash-latest')
except Exception:
    st.error("Chave da API do Google n√£o configurada.")
    st.stop()

# =============================================================================
# 3. ARQUITETURA MULTI-AGENTE 2.0
# =============================================================================

def agent_onboarding(df):
    """Analisa o dataframe (info e describe) e gera insights proativos."""
    info_buffer = io.StringIO()
    df.info(buf=info_buffer)
    df_info = info_buffer.getvalue()
    df_describe = df.describe().to_markdown()

    prompt = f"""
    Voc√™ √© um Analista de Dados Estrat√©gico. Sua miss√£o √© realizar uma an√°lise explorat√≥ria inicial (EDA) em um novo conjunto de dados e apresentar suas descobertas de forma proativa.

    **Estrutura dos Dados (df.info()):**
    ---
    {df_info}
    ---
    **Resumo Estat√≠stico (df.describe()):**
    ---
    {df_describe}
    ---
    **Amostra dos Dados (df.head()):**
    ---
    {df.head().to_markdown()}
    ---

    Com base em TODAS as informa√ß√µes acima, realize as seguintes tarefas:
    1.  **Resumo Executivo:** Escreva um par√°grafo conciso sobre a natureza e o prop√≥sito prov√°vel deste conjunto de dados.
    2.  **Insights Iniciais:** Identifique 2-3 observa√ß√µes interessantes diretamente das estat√≠sticas. Aponte para poss√≠veis anomalias, distribui√ß√µes not√°veis ou correla√ß√µes impl√≠citas (ex: "A m√©dia da 'idade' √© 35, mas o valor m√°ximo √© 99, o que pode indicar outliers. A receita tem um grande desvio padr√£o, sugerindo vendas muito desiguais.").
    3.  **Perguntas Estrat√©gicas:** Formule uma lista de 3 perguntas inteligentes e acion√°veis que um l√≠der de neg√≥cios faria. Essas perguntas devem ir al√©m do √≥bvio e sugerir an√°lises mais profundas, incluindo visualiza√ß√µes (ex: "Qual √© a correla√ß√£o entre 'investimento_marketing' e 'receita'?", "Como as vendas se distribuem por categoria de produto em um gr√°fico de barras?").
    """
    response = model.generate_content(prompt)
    return response.text

def agent_router(query, chat_history):
    """O c√©rebro do sistema. Decide qual ferramenta usar."""
    history_str = "\n".join([f"{msg['role']}: {msg['content']}" for msg in chat_history])
    
    prompt = f"""
    Voc√™ √© um agente roteador de IA. Sua fun√ß√£o √© analisar a pergunta do usu√°rio e o hist√≥rico da conversa para decidir qual ferramenta √© a mais apropriada para a tarefa.

    **Ferramentas Dispon√≠veis:**
    1. `gerar_codigo_pandas`: Use para perguntas que podem ser respondidas com um c√°lculo, uma tabela, um n√∫mero ou texto. Exemplos: "qual a m√©dia de idade?", "liste os 5 produtos mais vendidos", "qual o total de vendas?".
    2. `gerar_codigo_visualizacao`: Use para perguntas que pedem explicitamente por um gr√°fico ou implicam uma an√°lise visual. Exemplos: "mostre-me um gr√°fico de barras", "qual a distribui√ß√£o da idade?", "plote a s√©rie temporal de vendas", "crie um histograma".

    **Hist√≥rico da Conversa:**
    {history_str}

    **Pergunta Atual do Usu√°rio:**
    "{query}"

    Com base na pergunta atual e no contexto do hist√≥rico, qual ferramenta voc√™ deve usar?
    Responda APENAS com um objeto JSON contendo duas chaves: "ferramenta" e "pergunta_refinada".
    A "pergunta_refinada" deve ser a pergunta do usu√°rio, possivelmente enriquecida com o contexto do hist√≥rico.

    Exemplo de Resposta 1:
    {{"ferramenta": "gerar_codigo_pandas", "pergunta_refinada": "Qual √© a m√©dia de idade dos clientes no Brasil?"}}

    Exemplo de Resposta 2:
    {{"ferramenta": "gerar_codigo_visualizacao", "pergunta_refinada": "Gerar um gr√°fico de barras mostrando o total de vendas por categoria de produto"}}
    """
    response = model.generate_content(prompt)
    try:
        # Limpa a resposta para garantir que seja um JSON v√°lido
        cleaned_response = response.text.strip().replace("```json", "").replace("```", "")
        return json.loads(cleaned_response)
    except (json.JSONDecodeError, AttributeError):
        # Fallback se o LLM n√£o retornar um JSON v√°lido
        return {"ferramenta": "gerar_codigo_pandas", "pergunta_refinada": query}


def tool_code_generator(query, df_head):
    """Ferramenta que gera c√≥digo Pandas."""
    prompt = f"""
    Voc√™ √© um especialista em Python e Pandas. Gere c√≥digo para responder √† pergunta.
    DataFrame: `df`.
    Amostra:
    {df_head.to_markdown()}
    Pergunta: "{query}"
    Gere APENAS o c√≥digo Python. O resultado final DEVE ser armazenado na vari√°vel `resultado`.
    """
    response = model.generate_content(prompt)
    # <-- MUDAN√áA: L√≥gica de sanitiza√ß√£o para remover texto extra e Markdown
    raw_code = response.text
    cleaned_code = raw_code.replace("```python", "").replace("```", "").strip()
    return cleaned_code

def tool_visualization_generator(query, df_head):
    """Ferramenta que gera c√≥digo de visualiza√ß√£o."""
    # <-- MUDAN√áA: Removida a formata√ß√£o Markdown (**) do prompt
    prompt = f"""
    Voc√™ √© um especialista em visualiza√ß√£o de dados com Python, Matplotlib e Seaborn.
    Gere c√≥digo para criar uma visualiza√ß√£o que responda √† pergunta do usu√°rio.
    Use o DataFrame `df`.
    Amostra:
    {df_head.to_markdown()}
    Pergunta: "{query}"

    Instru√ß√µes Cruciais:
    1. Importe `matplotlib.pyplot as plt` e `seaborn as sns`.
    2. Crie a figura e os eixos (ex: `fig, ax = plt.subplots()`).
    3. Gere o gr√°fico usando `ax`. Adicione t√≠tulos e r√≥tulos claros.
    4. N√ÉO use `plt.show()`.
    5. O seu c√≥digo DEVE retornar a figura gerada na vari√°vel `resultado` (ex: `resultado = fig`).
    
    Gere APENAS o c√≥digo Python.
    """
    response = model.generate_content(prompt)
    # L√≥gica de sanitiza√ß√£o para remover texto extra e Markdown
    raw_code = response.text
    cleaned_code = raw_code.replace("```python", "").replace("```", "").strip()
    return cleaned_code

def agent_results_synthesizer(query, code_result):
    """Sintetiza resultados textuais."""
    # Implementa√ß√£o simplificada para manter o foco na l√≥gica principal
    return f"**An√°lise para a pergunta:** '{query}'\n\n**Resultado:**\n\n```\n{str(code_result)}\n```"

# =============================================================================
# 4. FUN√á√ïES AUXILIARES
# =============================================================================
def load_csv_from_zip(zip_file):
    try:
        with zipfile.ZipFile(zip_file, 'r') as z:
            csv_filename = next((name for name in z.namelist() if name.lower().endswith('.csv')), None)
            if csv_filename:
                with z.open(csv_filename) as f:
                    return pd.read_csv(f, on_bad_lines='skip')
            return None
    except Exception:
        return None

# =============================================================================
# 5. L√ìGICA DA INTERFACE E ESTADO DA SESS√ÉO
# =============================================================================
if "messages" not in st.session_state:
    st.session_state.messages = []
if "df" not in st.session_state:
    st.session_state.df = None

st.title("üçè Data Insights Pro")
st.markdown("Seu parceiro de an√°lise estrat√©gica, com a tecnologia Gemini 1.5.")
st.markdown("---")

if st.session_state.df is None:
    st.info("Para come√ßar, carregue um arquivo `.zip` contendo um `.csv`.")
    uploaded_file = st.file_uploader("Arraste seu arquivo aqui", type="zip", label_visibility="collapsed")
    if uploaded_file:
        with st.spinner("Realizando an√°lise explorat√≥ria inicial..."):
            df = load_csv_from_zip(uploaded_file)
            if df is not None:
                st.session_state.df = df
                st.session_state.messages = []
                welcome_message = agent_onboarding(df)
                st.session_state.messages.append({"role": "assistant", "content": welcome_message})
                st.rerun()
            else:
                st.error("Nenhum arquivo .csv encontrado no .zip.")
else:
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if isinstance(message["content"], str):
                st.markdown(message["content"])
            else: # Se for um gr√°fico
                st.pyplot(message["content"])

    if prompt := st.chat_input("Fa√ßa uma pergunta ou pe√ßa um gr√°fico..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("Analisando e decidindo a melhor abordagem..."):
                try:
                    # Roteador decide qual ferramenta usar
                    router_decision = agent_router(prompt, st.session_state.messages)
                    ferramenta = router_decision.get("ferramenta")
                    pergunta_refinada = router_decision.get("pergunta_refinada", prompt)

                    st.write(f"ü§ñ *Decis√£o do Agente: Usando a ferramenta `{ferramenta}`...*")
                    
                    codigo_gerado = ""
                    if ferramenta == "gerar_codigo_visualizacao":
                        codigo_gerado = tool_visualization_generator(pergunta_refinada, st.session_state.df.head())
                    else: # Fallback para pandas
                        codigo_gerado = tool_code_generator(pergunta_refinada, st.session_state.df.head())
                    
                    # Executa o c√≥digo gerado
                    namespace = {
                        'df': st.session_state.df,
                        'plt': plt,
                        'sns': sns,
                        'pd': pd,
                        'io': io
                    }
                    exec(codigo_gerado, namespace)
                    resultado_bruto = namespace.get('resultado')

                    # Exibe o resultado apropriado
                    if isinstance(resultado_bruto, plt.Figure):
                        st.pyplot(resultado_bruto)
                        st.session_state.messages.append({"role": "assistant", "content": resultado_bruto})
                    else:
                        resposta_final = agent_results_synthesizer(pergunta_refinada, resultado_bruto)
                        st.markdown(resposta_final)
                        st.session_state.messages.append({"role": "assistant", "content": resposta_final})

                except Exception as e:
                    error_message = f"Desculpe, encontrei um erro. Tente reformular sua pergunta.\n\n**Detalhe t√©cnico:** `{e}`"
                    st.error(error_message)
                    st.session_state.messages.append({"role": "assistant", "content": error_message})
    
    st.markdown("---")
    if st.button("Analisar Novo Arquivo"):
        st.session_state.df = None
        st.session_state.messages = []
        st.rerun()
