import streamlit as st
import pandas as pd
import zipfile
import google.generativeai as genai
import io
import matplotlib.pyplot as plt
import seaborn as sns
import json
from duckduckgo_search import DDGS

# =============================================================================
# 1. CONFIGURA√á√ÉO DA P√ÅGINA E ESTILO
# =============================================================================

st.set_page_config(
    layout="centered",
    page_title="Data Insights Pro", # T√≠tulo mais curto e elegante para a aba do navegador
    page_icon="üçè"
)

# Estilo CSS aprimorado para a est√©tica "Apple-like"
def load_css():
    st.markdown("""
    <style>
        /* Reset e Fontes */
        html, body, [class*="st-"] {
            font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, "Helvetica Neue", Arial, sans-serif;
            font-weight: 400;
        }
        
        /* T√≠tulos */
        h1 {
            font-weight: 600;
            letter-spacing: -0.03em;
        }
        
        /* Container Principal */
        .block-container {
            max-width: 720px; /* Largura ideal para leitura */
            padding-top: 3rem;
            padding-bottom: 3rem;
        }
        
        /* Mensagens de Chat */
        [data-testid="stChatMessage"] {
            border-radius: 20px;
            padding: 1rem 1.25rem;
            margin-bottom: 1rem;
            box-shadow: 0 2px 8px rgba(0,0,0,0.06);
            border: none;
        }
        
        /* Bot√µes */
        .stButton>button {
            border-radius: 10px;
            font-weight: 500;
        }
        
        /* Caixa de Upload de Arquivo */
        [data-testid="stFileUploader"] {
            border: 1.5px dashed #d0d0d5;
            background-color: #f8f8fa;
            border-radius: 12px;
            padding: 2rem;
        }
        
        /* Caixa de Informa√ß√£o (st.info) */
        [data-testid="stAlert"] {
            border-radius: 12px;
            border: none;
            background-color: #f0f0f5;
        }
    </style>
    """, unsafe_allow_html=True)

load_css()

# =============================================================================
# 2. CONFIGURA√á√ÉO DO MODELO DE IA (GEMINI)
# =============================================================================
try:
    GOOGLE_API_KEY = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=GOOGLE_API_KEY)
    model = genai.GenerativeModel('gemini-1.5-pro-latest')
except Exception:
    st.error("Chave da API do Google n√£o configurada.")
    st.stop()

# =============================================================================
# 3. DEFINI√á√ÉO DAS FERRAMENTAS (TOOLS)
# =============================================================================
# Cada fun√ß√£o √© uma ferramenta que o agente pode escolher usar.
# As docstrings s√£o CRUCIAIS, pois o LLM as usa para decidir qual ferramenta chamar.

def python_code_interpreter(code: str, scope: str):
    """
    Executa c√≥digo Python (Pandas, Matplotlib) em um escopo de dados espec√≠fico.
    Use esta ferramenta para qualquer tipo de c√°lculo, manipula√ß√£o ou visualiza√ß√£o de dados.
    O c√≥digo deve usar um DataFrame chamado `df`.
    O resultado da execu√ß√£o deve ser armazenado em uma vari√°vel chamada `resultado`.
    Retorna o resultado da execu√ß√£o ou uma mensagem de erro.
    """
    try:
        # Prepara o DataFrame ativo com base no escopo
        if scope == "Analisar Todos em Conjunto":
            active_df = pd.concat(st.session_state.dataframes.values(), ignore_index=True)
        else:
            active_df = st.session_state.dataframes[scope]
        
        namespace = {'df': active_df, 'plt': plt, 'sns': sns, 'pd': pd, 'io': io}
        exec(code, namespace)
        return namespace.get('resultado', "C√≥digo executado, mas sem resultado expl√≠cito.")
    except Exception as e:
        return f"Erro ao executar o c√≥digo: {e}"

def web_search(query: str):
    """
    Realiza uma busca na web para encontrar informa√ß√µes atuais ou de conhecimento geral.
    Use para perguntas sobre cota√ß√µes de moeda, defini√ß√µes, not√≠cias ou qualquer coisa que n√£o esteja nos dados.
    """
    with DDGS() as ddgs:
        results = [r['body'] for r in ddgs.text(query, max_results=3)]
    return "\n".join(results) if results else "Nenhum resultado encontrado."

def list_available_data():
    """
    Lista todos os arquivos de dados (CSVs) que foram carregados e est√£o dispon√≠veis para an√°lise.
    """
    if not st.session_state.dataframes:
        return "Nenhum arquivo de dados foi carregado ainda."
    return f"Os seguintes arquivos est√£o dispon√≠veis: {', '.join(st.session_state.dataframes.keys())}"

def get_data_schema(filename: str):
    """
    Fornece o esquema (nomes das colunas e tipos de dados) de um arquivo de dados espec√≠fico.
    """
    if filename not in st.session_state.dataframes:
        return f"Erro: O arquivo '{filename}' n√£o foi encontrado."
    df = st.session_state.dataframes[filename]
    buffer = io.StringIO()
    df.info(buf=buffer)
    return buffer.getvalue()

# Dicion√°rio de ferramentas para f√°cil acesso
TOOLS = {
    "python_code_interpreter": python_code_interpreter,
    "web_search": web_search,
    "list_available_data": list_available_data,
    "get_data_schema": get_data_schema
}

# =============================================================================
# 4. O AGENTE EXECUTOR (ReAct)
# =============================================================================

def agent_executor(query, chat_history, scope):
    """O c√©rebro do sistema. Usa o modelo ReAct para pensar e usar ferramentas."""
    
    # RAG: Recupera√ß√£o de contexto relevante
    context = f"""
    **Contexto Atual da An√°lise:**
    - Escopo Selecionado: {scope}
    - Arquivos Dispon√≠veis: {list(st.session_state.dataframes.keys())}
    - Hist√≥rico da Conversa: {"".join([f'{m["role"]}: {m["content"]}\\n' for m in chat_history])}
    """

    prompt = f"""
    Voc√™ √© um Analista de Dados Aut√¥nomo. Sua miss√£o √© responder √† pergunta do usu√°rio usando um ciclo de Pensamento-A√ß√£o-Observa√ß√£o (ReAct).
    Voc√™ tem acesso a um conjunto de ferramentas e deve decidir qual usar para cada passo.

    {context}

    **Ferramentas Dispon√≠veis:**
    - `python_code_interpreter(code: str, scope: str)`: Executa c√≥digo Python para an√°lise de dados.
    - `web_search(query: str)`: Busca informa√ß√µes na web.
    - `list_available_data()`: Lista os arquivos de dados carregados.
    - `get_data_schema(filename: str)`: Obt√©m as colunas de um arquivo espec√≠fico.

    **Ciclo de Trabalho:**
    1.  **Thought:** Descreva seu plano passo a passo. O que voc√™ precisa saber? Qual ferramenta o ajudar√° a obter essa informa√ß√£o?
    2.  **Action:** Escolha UMA ferramenta e formule a entrada para ela em um formato JSON.
        Exemplo de A√ß√£o:
        ```json
        {{"tool": "web_search", "tool_input": "cota√ß√£o atual BRL para USD"}}
        ```
    3.  O sistema executar√° a ferramenta e voc√™ receber√° uma **Observation**.
    4.  Repita o ciclo Pensamento-A√ß√£o at√© ter informa√ß√µes suficientes para responder √† pergunta original.
    5.  Quando tiver a resposta final, seu √∫ltimo pensamento deve ser "Eu tenho a resposta final." e a A√ß√£o deve ser um JSON com a ferramenta "final_answer" e a resposta completa.
        ```json
        {{"tool": "final_answer", "tool_input": "A resposta final √©..."}}
        ```

    **Inicie o processo.**

    **Pergunta do Usu√°rio:** "{query}"
    """
    
    response = model.generate_content(prompt)
    try:
        # Extrai o JSON da resposta do LLM
        json_part = response.text.split("```json").split("```")[0]
        action_json = json.loads(json_part)
        return action_json, response.text # Retorna a a√ß√£o e o pensamento completo
    except (IndexError, json.JSONDecodeError):
        # Fallback se o LLM n√£o seguir o formato
        return {"tool": "final_answer", "tool_input": f"Desculpe, tive um problema ao formular um plano de a√ß√£o. A resposta do modelo foi: {response.text}"}, response.text

# =============================================================================
# 5. L√ìGICA DA INTERFACE E ESTADO DA SESS√ÉO
# =============================================================================

# Inicializa√ß√£o do estado da sess√£o para garantir que as vari√°veis existam
if "messages" not in st.session_state:
    st.session_state.messages = []
if "dataframes" not in st.session_state:
    st.session_state.dataframes = None
if "active_scope" not in st.session_state:
    st.session_state.active_scope = "Nenhum"

# --- L√ìGICA DE LAYOUT CONDICIONAL ---

# Se nenhum arquivo foi carregado, mostra a interface de UPLOAD.
if st.session_state.dataframes is None:
    
    # T√≠tulo e Slogan
    st.title("üçè Data Insights Pro")
    st.markdown("##### Um universo de dados em um √∫nico lugar. Pergunte, explore, descubra.")
    st.markdown("---")
    
    # √Årea de Upload Centralizada
    st.info("Para come√ßar, carregue um arquivo `.zip` contendo um ou mais arquivos `.csv`.")
    uploaded_file = st.file_uploader(
        "Arraste seu cat√°logo de dados aqui ou clique para procurar", 
        type="zip", 
        label_visibility="collapsed"
    )
    
    if uploaded_file:
        with st.spinner("Catalogando e analisando seus arquivos..."):
            # Use a fun√ß√£o de carregar m√∫ltiplos dataframes
            dfs = load_dataframes_from_zip(uploaded_file) 
            if dfs:
                st.session_state.dataframes = dfs
                st.session_state.messages = []
                # Use a fun√ß√£o de onboarding que lida com m√∫ltiplos arquivos
                welcome_message = agent_onboarding(dfs) 
                st.session_state.messages.append({"role": "assistant", "content": welcome_message})
                st.session_state.active_scope = "Analisar Todos em Conjunto"
                st.rerun()
            else:
                st.error("Nenhum arquivo .csv encontrado no .zip.")

# Se arquivos J√Å foram carregados, mostra a interface de CHAT.
else:
    # Cabe√ßalho do Chat
    st.title("üçè Conversando com seus Dados")

    # Seletor de escopo e bot√£o de reset em colunas para organiza√ß√£o
    col1, col2 = st.columns([3, 1])
    with col1:
        scope_options = ["Analisar Todos em Conjunto"] + list(st.session_state.dataframes.keys())
        st.session_state.active_scope = st.selectbox(
            "Escopo da An√°lise:",
            options=scope_options,
            index=scope_options.index(st.session_state.active_scope),
            label_visibility="collapsed"
        )
    with col2:
        if st.button("Analisar Outro", use_container_width=True):
            st.session_state.dataframes = None
            st.session_state.messages = []
            st.session_state.active_scope = "Nenhum"
            st.rerun()
    
    st.markdown("---")

    # Exibe o hist√≥rico de mensagens
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if isinstance(message["content"], str):
                st.markdown(message["content"])
            elif "thought" in message["content"]: # Para exibir o racioc√≠nio do agente
                 with st.expander("Ver o Racioc√≠nio do Agente"):
                    st.markdown(message["content"]["thought"])
            else: # Para exibir gr√°ficos
                st.pyplot(message["content"])

    # Captura a nova pergunta do usu√°rio
    if prompt := st.chat_input(f"Pergunte sobre '{st.session_state.active_scope}'..."):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        # Processa a pergunta com os agentes
        with st.chat_message("assistant"):
            with st.spinner("Pensando..."):
                try:
                    # L√≥gica de execu√ß√£o do agente (ReAct)
                    action_json, thought_process = agent_executor(prompt, st.session_state.messages, st.session_state.active_scope)
                    
                    st.session_state.messages.append({"role": "assistant", "content": {"thought": thought_process}})
                    with st.expander("Ver o Racioc√≠nio do Agente"):
                        st.markdown(thought_process)

                    tool_name = action_json.get("tool")
                    tool_input = action_json.get("tool_input")
                    
                    if tool_name == "final_answer":
                        final_response = tool_input
                    elif tool_name in TOOLS:
                        tool_output = TOOLS[tool_name](tool_input, scope=st.session_state.active_scope) if tool_name == "python_code_interpreter" else TOOLS[tool_name](tool_input)
                        
                        final_response = f"**Resultado da Ferramenta `{tool_name}`:**\n\n"
                        if isinstance(tool_output, plt.Figure):
                            st.pyplot(tool_output)
                            st.session_state.messages.append({"role": "assistant", "content": tool_output})
                            final_response = None
                        else:
                            final_response += str(tool_output)
                    else:
                        final_response = "Desculpe, o agente escolheu uma ferramenta desconhecida."

                    if final_response:
                        st.markdown(final_response)
                        st.session_state.messages.append({"role": "assistant", "content": final_response})

                except Exception as e:
                    error_message = f"Ocorreu um erro cr√≠tico no ciclo do agente.\n\n**Detalhe t√©cnico:** `{e}`"
                    st.error(error_message)
                    st.session_state.messages.append({"role": "assistant", "content": error_message})

    if st.button("Analisar Novo Cat√°logo de Dados"):
        # ... (c√≥digo do bot√£o id√™ntico ao anterior)
        pass
